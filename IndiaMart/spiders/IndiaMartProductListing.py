from bs4 import BeautifulSoup
from json import loads
from scrapy import Request, Spider
from scrapy.http import Response
from typing import Dict, Generator


class IndiaMartProductListing(Spider):
    """
    Scrapy Spider to extract product listings from sub-sub-category pages on IndiaMART.

    Reads sub-sub-category URLs and associated category lineage from a JSON file generated by a previous spider.

    Attributes:
        name (str): Unique spider name used by Scrapy to identify this spider.
        path (str): Path to the JSON file containing:
                    - category (str)
                    - sub_category (str)
                    - sub_sub_category (str)
                    - sub_sub_category_url (str)
    """

    name = "IndiaMartProductListing"

    def __init__(self, path: str = "sub_sub_category_data.json"):
        """
        Initialize the spider with a path to the input file.

        Parameters:
            path (str): Path to the JSON file containing sub-sub-category data.
        """

        self.path = path

    def start_requests(self):
        """
        Reads target sub-sub-category URLs and metadata from a JSON file and sends Scrapy requests.

        Yields:
            Request: Scrapy Request objects with metadata for category lineage and target URLs.
        """

        try:
            with open(self.path, "r", encoding="utf-8") as file:
                entries = loads(file.read())  # List[Dict[str, str]]

                for entry in entries:
                    category = entry.get("category")
                    sub_category = entry.get("sub_category")
                    sub_sub_category = entry.get("sub_sub_category")
                    sub_sub_category_url = entry.get("sub_sub_category_url")

                    if not (category and sub_category and sub_sub_category and sub_sub_category_url):
                        self.logger.warning(f"Skipping incomplete entry: {entry}")
                        continue

                    yield Request(
                        url=sub_sub_category_url,
                        callback=self.parse,
                        meta={
                            "category": category,
                            "sub_category": sub_category,
                            "sub_sub_category": sub_sub_category
                        },
                        dont_filter=True
                    )
        except FileNotFoundError:
            self.logger.error(f"{self.path} file not found.")
        except Exception as e:
            self.logger.error(f"Failed to parse {self.path}: {e}")

    def parse(self, response: Response) -> Generator[Dict[str, str], None, None]:
        """
        Parses product data from the IndiaMART sub-sub-category pages.

        Parameters:
            response (Response): The response object.

        Yields:
            dict: A dictionary containing:
                - category (str): Main category name.
                - sub_category (str): Sub-category name.
                - sub_sub_category (str): Sub-sub-category name.
                - product (str): Name of the product.
                - price (str): Price of the product.
                - url (str): Fully resolved URL for the product page.
        """

        soup = BeautifulSoup(response.text, "lxml")

        category = response.meta.get("category")
        sub_category = response.meta.get("sub_category")
        sub_sub_category = response.meta.get("sub_sub_category")

        div_tags = soup.find_all("div", attrs={"class": "absltdiv bgw"})
        for div_tag in div_tags:
            li_tags = div_tag.find_all("li", attrs={"class": "mListPrc"})
            for li_tag in li_tags:
                a_tag = li_tag.find("a")
                if not a_tag:
                    continue

                url = a_tag.get("href", "").strip()
                h3_tag = li_tag.find("h3")
                product = h3_tag.text.strip() if h3_tag else None

                price_tag = li_tag.find("span", class_="prc cp tcur")
                price = price_tag.get_text(separator=" ", strip=True) if price_tag else None

                yield {
                    "category": category,
                    "sub_category": sub_category,
                    "sub_sub_category": sub_sub_category,
                    "product": product,
                    "price": price,
                    "url": url
                }
